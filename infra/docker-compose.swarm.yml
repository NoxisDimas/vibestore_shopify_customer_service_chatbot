version: '3.8'

# ============================================
# DOCKER SWARM MODE WITH SECRETS
# ============================================
# Deploy with:
#   docker swarm init
#   docker stack deploy -c docker-compose.swarm.yml cs-agent
#
# Create secrets first:
#   echo "your-openai-key" | docker secret create openai_api_key -
#   echo "your-groq-key" | docker secret create groq_api_key -
#   echo "your-api-key" | docker secret create api_key -
#   echo "postgresql://..." | docker secret create postgres_uri -
#   echo "neo4j-password" | docker secret create neo4j_password -
#   echo "langsmith-key" | docker secret create langsmith_api_key -
# ============================================

services:
  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    configs:
      - source: nginx_config
        target: /etc/nginx/nginx.conf
    depends_on:
      - app
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '0.25'
          memory: 128M

  # Main Application
  app:
    image: ${DOCKER_REGISTRY:-}cs-agent-app:${VERSION:-latest}
    build:
      context: ..
      dockerfile: infra/Dockerfile
    secrets:
      - openai_api_key
      - groq_api_key
      - api_key
      - postgres_uri
      - langsmith_api_key
    environment:
      - ENVIRONMENT=prod
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OLLAMA_BASE_URL=http://ollama:11434
      - LIGHTRAG_API_URL=http://lightrag:9621
      - LANGSMITH_TRACING=true
      - LANGSMITH_PROJECT=${LANGSMITH_PROJECT:-production}
      - LANGSMITH_ENDPOINT=https://api.smith.langchain.com
    depends_on:
      - qdrant
      - postgres
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  # Streamlit UI
  streamlit:
    image: ${DOCKER_REGISTRY:-}cs-agent-app:${VERSION:-latest}
    command: streamlit run app/ui/streamlit_app.py --server.address 0.0.0.0 --server.headless true
    environment:
      - API_URL=http://app:8000
      - LIGHTRAG_API_URL=http://lightrag:9621
    depends_on:
      - app
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '0.50'
          memory: 512M

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=128
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G

  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.11
    secrets:
      - neo4j_password
    environment:
      - NEO4J_AUTH=neo4j/$(cat /run/secrets/neo4j_password)
    volumes:
      - neo4j_data:/data
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G

  # LightRAG Service
  lightrag:
    image: ${DOCKER_REGISTRY:-}cs-agent-lightrag:${VERSION:-latest}
    build:
      context: ..
      dockerfile: infra/Dockerfile.lightrag
    secrets:
      - groq_api_key
      - neo4j_password
    environment:
      - EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-mxbai-embed-large}
      - EMBEDDING_BINDING=ollama
      - EMBEDDING_BINDING_HOST=http://ollama:11434
      - LLM_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      - LLM_BINDING=openai
      - LLM_BINDING_HOST=https://api.groq.com/openai/v1
      - LIGHTRAG_VECTOR_STORAGE=QdrantVectorDBStorage
      - LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
      - QDRANT_URL=http://qdrant:6333
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
    volumes:
      - lightrag_data:/data
    depends_on:
      - qdrant
      - neo4j
      - ollama
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 4G

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    secrets:
      - postgres_password
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_DB=agent_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G

  # Ollama LLM Server
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

# ============================================
# SECRETS (External - must be created first)
# ============================================
secrets:
  openai_api_key:
    external: true
  groq_api_key:
    external: true
  api_key:
    external: true
  postgres_uri:
    external: true
  postgres_password:
    external: true
  neo4j_password:
    external: true
  langsmith_api_key:
    external: true
  # Optional secrets (create if needed)
  # whatsapp_access_token:
  #   external: true
  # telegram_bot_token:
  #   external: true

  # ============================================
  # CONFIGS
  # ============================================
configs:
  nginx_config:
    file: ./nginx.conf

# ============================================
# VOLUMES
# ============================================
volumes:
  qdrant_data:
  neo4j_data:
  lightrag_data:
  postgres_data:
  ollama_data:

    # ============================================
    # NETWORKS
    # ============================================
networks:
  default:
    driver: overlay
    attachable: true
