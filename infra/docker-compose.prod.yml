services:
  # Nginx Load Balancer (entry point)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost/nginx-health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  app:
    restart: always
    environment:
      - ENVIRONMENT=prod
    deploy:
      replicas: 3 # 3 instances x 4 workers = 12 total workers
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  streamlit:
    restart: always
    command: streamlit run app/ui/streamlit_app.py --server.address 0.0.0.0 --server.headless true --browser.gatherUsageStats false --server.baseUrlPath=/admin
    environment:
      - API_URL=http://app:8000
      - LIGHTRAG_API_URL=http://lightrag:9621
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin123}
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M

  qdrant:
    restart: always
    deploy:
      resources:
        limits:
          memory: 2G

  neo4j:
    restart: always
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
    deploy:
      resources:
        limits:
          memory: 2G

  lightrag:
    restart: always
    environment:
      - LOG_LEVEL=WARNING
      - LLM_BINDING=openai
      - LLM_BINDING_HOST=https://api.groq.com/openai/v1
      - LLM_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      - LLM_BINDING_API_KEY=${GROQ_API_KEY}
    deploy:
      resources:
        limits:
          memory: 4G

  postgres:
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G

  ollama:
    restart: always
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

networks:
  default:
    driver: bridge
